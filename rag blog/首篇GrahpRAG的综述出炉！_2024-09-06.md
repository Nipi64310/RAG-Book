嘿，大家好！这里是一个专注于AI智能体的频道！

GraphRAG在国内爆火也没多久，这么快就出综述了，大神们的键盘得敲出火花了。

> Graph Retrieval-Augmented Generation: A Survey

> 最近，检索增强生成 （RAG） 在解决大型语言模型 （LLM） 的挑战方面取得了显著的成功，而无需重新训练。通过引用外部知识库，RAG 优化了 LLM 输出，有效缓解了“幻觉”、缺乏特定领域知识和过时信息等问题。然而，数据库中不同实体之间关系的复杂结构给RAG系统带来了挑战。作为回应，GraphRAG 利用跨实体的结构信息来实现更精确、更全面的检索，捕获关系知识并促进更准确、上下文感知的响应。鉴于 GraphRAG 的新颖性和潜力，对当前技术进行系统回顾势在必行。本文首次全面概述了 GraphRAG 方法。**我们将 GraphRAG 工作流程正式化，包括基于Graph的索引、Graph-guided的检索和GraphRAG。然后，我们概述了每个阶段的核心技术和训练方法。此外，我们还研究了 GraphRAG 的下游任务、应用领域、评估方法和工业用例。** 最后，我们探讨了未来的研究方向，以激发进一步的探究并推动该领域的进展。



大模型LLM虽然非常非常的厉害，但是有时候也会犯迷糊，比如它们可能会编造一些不存在的信息，这就是所谓的“幻觉”问题。而且，它们可能对某些专业领域不够了解，或者用到的信息不够新。为了解决这些问题，研究者们提出了一种新方法，叫做检索增强生成（RAG）。这个方法通过在生成过程中加入一个检索组件，可以让模型在回答问题时，先去一个巨大的文本库里面找相关信息，然后再结合这些信息给出答案。这样一来，不仅答案的内容更丰富，而且准确性也更高。

但是，这个方法也有它的局限性。比如，它可能没有很好地利用数据库里不同实体之间复杂的关系。于是，图检索增强生成（GraphRAG）就应运而生了。GraphRAG利用了实体之间的结构信息，让检索过程更精确，更全面。


![](https://files.mdnice.com/user/50285/0406cf3c-a4b7-414f-8682-66b9969ff34d.png)


那GraphRAG到底是怎么一回事？ 想象一下，你有一个问题，但是要回答这个问题需要很多相关的信息。GraphRAG就像是一个超级助手，它首先会在一个图数据库里找到所有相关的信息，然后帮你整理好，最后用这些信息来回答你的问题。

这个过程可以分为三个阶段：首先是Graph-Based Indexing，就是建立和组织图数据库，让信息可以快速被检索到。接着是Graph-Guided Retrieval，这一阶段GraphRAG会根据你的问题，从图数据库中找到最相关的信息。最后是Graph-Enhanced Generation）
，这一阶段就是用找到的信息来生成答案。

![](https://files.mdnice.com/user/50285/0f489aa7-cedd-4eb4-83b1-1f50d6c95551.png)

### **Graph-Based Indexing**

GraphRAG的工作中，首先，它得有个强大的“大脑”，也就是图数据库。想象一下，你要在一个巨大的图书馆里找到一本书，如果没有好的目录和索引，那得找到猴年马月去。图索引就是这个图书馆的目录，帮GraphRAG快速定位信息。

图数据的来源有public和private 2种，就像是选书一样，我们得决定是去学校图书馆借书，还是自己买书建个私人图书馆。在这里，“公共图书馆”就是开放的知识图谱，比如维基百科、百度百科这些，大家都能用。而“私人图书馆”则是自己构建的图数据，可能针对特定领域，比如医学、法律这些。

有了图数据之后，我们得给这些数据建立索引。这里提到了三种主要的索引方法：图索引、文本索引和向量索引。

- 图索引就是保留图的全部结构，这样任何时候你都能快速找到节点和它的邻居节点。
- 文本索引则是把图数据转换成文本描述，就像是给每本书写个简介，然后用文本检索技术来找信息。
- 向量索引则是把图数据转换成向量，这样可以用一些高效的算法来快速检索。

这些索引方法各有优点，实际应用中通常会混合使用，就像是图书馆里既有目录，也有电子检索系统，还有图书推荐系统一样。

### **Graph-Guided Retrieval**

![](https://files.mdnice.com/user/50285/9d5a86b9-7bc3-4e12-aeca-0c499a52fe30.png)

在确定图数据和索引之后，那下一步就是怎么找到我们需要的信息吗？

检索器retriever可以分为三种类型：

- **非参数检索器**：用一些规则或者算法来找信息，它们不需要训练。
- **基于语言模型的检索器**：常见的向量搜索属于这个范畴。
- **基于图神经网络的检索器**：能处理复杂的图结构，它们能理解信息之间的关系，帮我们找到最合适的信息。

接下来，我们得决定怎么“搜索”。这里有几个不同的策略：

- **一次性检索**：就像一次性把超市里所有需要的东西都买齐一样，这种方法尝试一次就找到所有相关的信息。
- **迭代检索**：这就像是我们在解题时，一步步地找到答案。每次找到一些信息后，根据这些信息再去找更多的信息，直到找到满意的答案。
- **多阶段检索**：这个方法就像是我们做项目，分成好几个阶段来完成。每个阶段可能用不同的检索器，一步步精细化我们的搜索。

然后，我们还得决定要搜索的“粒度”，也就是我们要找的信息的详细程度。我们可以找单个的节点、节点对（三元组）、路径或者整个子图。

最后，我们还得有一些技巧来提高我们的搜索质量，比如通过扩展问题或者合并、剪枝找到的信息来优化搜索结果。

**Graph-Enhanced Generation**

![](https://files.mdnice.com/user/50285/dc68fd3b-0027-4ccb-887d-7a9cc16ab383.png)

现在我们来到了GraphRAG的最后一个阶段，也就是我们的生成器。分为2种， GNN or LMs， 前者可以理解图结构得数据，后者的输入，必须得转换成自然语言能理解得格式。

那怎么把图数据转换成LLMs能理解的格式呢？ 还是有2种方式
![](https://files.mdnice.com/user/50285/73bb0d15-b0f4-4b10-95d8-be9a6019d6d3.png)
- **graph languages**：如上图，我们可以把图数据转换成自然语言描述。或者用代码形式、节点序列或者树状图来表示。

- **图嵌入**：这是一种更高级的方法，我们把图数据压缩成一个个小的向量，挑战在于如何结合图像量和文本数据。

最后，是关于GraphRAG系统的训练和应用。

关于训练部分同RAG一样，3种训练模式
- 使用现成的模型来直接解决问题，这些模型可能依靠一些规则或者已经预训练好的语言模型。但这种方法可能不够完美，因为它们可能没有针对我们要解决的具体问题进行优化。
- 用一些有监督的信号来独立训练我们的模型，让它们能够更好地适应特定的任务。
- 联合训练，在GraphRAG中，这意味着我们同时训练检索器和生成器，让它们能够更好地协同工作。

业界的GraphRAG系统
- GraphRAG(by Microsoft)  https://github.com/microsoft/graphrag
- GraphRAG (by NebulaGraph) https://www.nebula-graph.io/posts/graph-RAG
- GraphRAG (by Antgroup)   https://github.com/eosphoros-ai/DB-GPT
- NallM (by Neo4j)  https://github.com/neo4j/NaLLM
- LLMGraphBuilder (by Neo4j)  https://github.com/neo4j-labs/llm-graph-builder


好了，这就是我今天想分享的内容。如果你对构建AI智能体感兴趣，别忘了点赞、关注噢~