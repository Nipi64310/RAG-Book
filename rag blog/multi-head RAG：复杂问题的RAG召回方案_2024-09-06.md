论文笔记分享，标题是 Multi-Head RAG: Solving Multi-Aspect Problems with LLMs

**这个工作要解决个什么问题呢？** RAG 得流程是通过将文档召回，放入LLM的上下文中，来提供更准确和相关的答案。但是现有的 RAG 解决方案可能比较难处理，召回的内容来自完全不同的文档，因为这些文档在语义空间中可能很远，很难将它们全部检索出来。

论文中有张图如下图，正常的RAG在遇到query有点复杂的时候，在召回的时候就很麻烦。如果是纯粹的绿点主题或者黄点主题那都没太大问题。但是如果是复杂的多主题的，到向量空间之后就不好召回了。

![](https://files.mdnice.com/user/50285/ed995fb7-eea8-48e7-8f73-38b346c1e96d.png)

那咋整呢，大概的一个方案就是下图，query被拆解成了多个向量，每个向量比较纯粹，类似于多路召回，总能匹配到需要的chunk。
![](https://files.mdnice.com/user/50285/33929f68-7b4a-44d4-acd9-ce75f581f89f.png)


**怎么获取多个向量呢？**  MRAG通过使用Transformer的多头注意力层的特征作为向量表征，而不是仅使用取最后解码器层的输出，这样做的动机是不同的注意力头可以学习捕获数据的不同方面。每一层取一个向量，取最后一个位置的。chunks和query都生成多个向量，检索的时候，使用投票策略，结合了不同嵌入空间的重要性得分（根据一层的头内向量空间分布计算的），来选择最相关的文本块，并根据其重要性对检索结果进行加权。

![](https://files.mdnice.com/user/50285/0692f911-89a7-4b2b-8a80-dacf03225cff.png)


最后结果在召回的相关性方面获得了比较大的提升

![](https://files.mdnice.com/user/50285/8e0b5e24-5296-4699-af6e-d02b5347ec3a.png)

