嘿，大家好！这里是一个专注于AI智能体的频道~ 争取给家人们带来越来越多的干货！

今天给大家分享斯坦福大学最近的一项研究，探讨了如何利用LLMs从头开始撰写基础、结构良好的长篇文章，达到与维基百科页面相当的广度和深度。

> Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models

> 我们研究如何应用大型语言模型从头开始编写扎根且有组织的长篇文章，其广度和深度与维基百科页面相当。这个尚未充分探讨的问题在写作前阶段提出了新的挑战，包括如何在写作前研究主题并准备大纲。我们提出了STORM ，一种通过检索和多视角提问来合成主题大纲的写作系统。 STORM 通过以下方式对预写作阶段进行建模：(1) 在研究给定主题时发现不同的观点，(2) 模拟对话，持不同观点的作者向基于可信互联网来源的主题专家提出问题，(3) 整理收集到的信息创建一个轮廓。
为了进行评估，我们构造了 FreshWiki（最新高质量维基百科文章的数据集），并制定了大纲评估来评估预写作阶段。我们进一步收集经验丰富的维基百科编辑的反馈。与由大纲驱动的检索增强基线生成的文章相比，STORM 的更多文章被认为是有组织的（绝对增加了 25%）并且覆盖范围广泛（增加了 10%）。专家反馈还有助于识别生成接地气的长文章的新挑战，例如来源偏见转移和不相关事实的过度关联。


先整出来一个大纲，然后再写作。但是，这事儿说起来容易做起来难，因为你得先了解一大堆信息，然后才能写出大纲来。

当给定一个主题之后，它先去网上搜一堆类似主题的维基百科文章，然后琢磨出不同的视角。这样，它就能从多个角度提出问题，而不是只停留在表面。

接下来，STORM会模拟一场对话，就像两个人聊天一样。一边是“作家”，其实就是STORM自己，另一边是“专家”，这个专家是一个基于RAG的回答过程。

在对话中，STORM会根据话题、自己的视角和之前的对话内容，提出问题。然后，它会把这些问题变成搜索关键词，去找答案。找到的答案还得过一遍筛子，确保来源靠谱。

找到答案后，STORM会整理一下，形成一个答案。这个答案不仅会用来回应问题，还会存起来，以后写文章的时候用得上。

聊了一大堆后，STORM就对话题了解得差不多了。这时候，它会开始写大纲。先根据自己的理解，弄一个初步的版本，然后再结合之前的对话，把大纲做得更完整。
![](https://files.mdnice.com/user/50285/e72ddbb2-5c34-4132-be89-f392450f3dea.png)

最后，在预写阶段创建的大纲和收集的参考资料的基础上，逐段撰写全文。每段都会根据语义相似性从参考资料中检索相关信息，并生成带有引用的文本。

在langgraph的tutorial中，已经有了这个算法的教程（虽然论文是上个月出的~，这也是上周推文中提到的agent是否要用框架一方面把。）

![](https://files.mdnice.com/user/50285/0bc0787d-a4e4-47bc-ba03-dbcf54f4f349.png)

代码地址见后文，具体内容不复制了，可以看看例子，

输入：“百万级上下文窗口语言模型对检索增强生成（RAG）的影响”
初始大纲：

![](https://files.mdnice.com/user/50285/f4185201-99bf-407b-b5d1-299ea60408ea.png)

扩展后很复杂：

![](https://files.mdnice.com/user/50285/5e83c8de-adde-4936-85b5-742eb37d9c9f.png)

最后写的有那味道了：
![](https://files.mdnice.com/user/50285/776a82cb-3794-48ab-b642-23da45338f39.png)


代码地址：https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/storm/storm.ipynb

好了，这就是我今天想分享的内容。如果你对构建AI智能体感兴趣，别忘了点赞、关注噢~